{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "zip argument #1 must support iteration",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-d4d0c2764c67>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;31m# 计算梯度并更新参数\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[0mgradients\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;31m# 打印当前损失值和参数值\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: zip argument #1 must support iteration"
     ]
    }
   ],
   "source": [
    "# 导入所需的库\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 设置随机种子以确保可重复性\n",
    "tf.random.set_seed(123)\n",
    "\n",
    "# 准备数据集\n",
    "x1 = np.random.randn(100)\n",
    "x2 = np.random.randn(100)\n",
    "y = 3 * x1 + 2 * x2 + 1 + 0.2 * np.random.randn(100)\n",
    "\n",
    "# 将数据集转换为张量格式\n",
    "x1_tensor = tf.constant(x1, dtype=tf.float32, name='x1')\n",
    "x2_tensor = tf.constant(x2, dtype=tf.float32, name='x2')\n",
    "y_tensor = tf.constant(y, dtype=tf.float32, name='y')\n",
    "\n",
    "# 将自变量合并为一个张量\n",
    "x_tensor = tf.stack([x1_tensor, x2_tensor], axis=1)\n",
    "\n",
    "# 定义模型参数变量\n",
    "w = tf.Variable(tf.random.normal(shape=(2, 1), mean=0.0, stddev=1.0), name='weights')\n",
    "b = tf.Variable(tf.zeros(shape=(1,), dtype=tf.float32), name='bias')\n",
    "\n",
    "# 定义损失函数\n",
    "def mse_loss(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "\n",
    "# 定义优化器\n",
    "optimizer = tf.optimizers.SGD(learning_rate=0.1)\n",
    "\n",
    "# 记录每个迭代步骤的损失值和参数值\n",
    "loss_history = []\n",
    "w1_history = []\n",
    "w2_history = []\n",
    "b_history = []\n",
    "\n",
    "# 进行梯度下降迭代优化\n",
    "for i in range(100):\n",
    "    # 计算当前预测值\n",
    "    y_pred = tf.matmul(x_tensor, w) + b\n",
    "    \n",
    "    # 计算当前损失值\n",
    "    loss = mse_loss(y_tensor, y_pred)\n",
    "    \n",
    "    # 记录损失值和参数值\n",
    "    loss_history.append(loss.numpy())\n",
    "    w1_history.append(w[0,0].numpy())\n",
    "    w2_history.append(w[1,0].numpy())\n",
    "    b_history.append(b.numpy()[0])\n",
    "    \n",
    "    # 计算梯度并更新参数\n",
    "    gradients = tf.GradientTape(loss, [w, b])\n",
    "    optimizer.apply_gradients(zip(gradients, [w, b]))\n",
    "    \n",
    "    # 打印当前损失值和参数值\n",
    "    if i % 10 == 0:\n",
    "        print('Epoch {:4d}: loss = {:.4f}, w1 = {:.4f}, w2 = {:.4f}, b = {:.4f}'.format(i, loss.numpy(), w[0,0].numpy(), w[1,0].numpy(), b.numpy()[0]))\n",
    "\n",
    "# 绘制自变量和因变量之间的关系图\n",
    "plt.scatter(x1, y, label='actual')\n",
    "plt.plot(x1, tf.matmul(x_tensor, w).numpy().flatten() + b.numpy()[0], color='red', label='predicted')\n",
    "plt.xlabel('x1')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 绘制损失值和参数值的变化图\n",
    "fig, axs = plt.subplots(2, 2, figsize=(12, 8))\n",
    "\n",
    "axs[0, 0].plot(loss_history)\n",
    "axs[0, 0].set_xlabel('Epoch')\n",
    "axs[0, 0].set_ylabel('Loss')\n",
    "\n",
    "axs[0, 1].plot(w1_history)\n",
    "axs[0, 1].set_xlabel('Epoch')\n",
    "axs[0, 1].set_ylabel('w1')\n",
    "\n",
    "axs[1, 0].plot(w2_history)\n",
    "axs[1, 0].set_xlabel('Epoch')\n",
    "axs[1, 0].set_ylabel('w2')\n",
    "\n",
    "axs[1, 1].plot(b_history)\n",
    "axs[1, 1].set_xlabel('Epoch')\n",
    "axs[1, 1].set_ylabel('b')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
